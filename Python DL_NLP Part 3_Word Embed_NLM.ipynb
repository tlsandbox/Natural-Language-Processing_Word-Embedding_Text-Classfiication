{
    "cells": [
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "# Python DL_NLP Crash Course  Part 3_Word Embeding with Word2Vec & GloVe\n\n## Full Day Workshop for user learn Data Science with Python\n### 2017 Dec Timothy CL Lam\nThis is meant for internal usage, part of contents copied externally, not for commercial purpose\n"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## The Word Embedding Model\n### Recently, the field of natural language processing has been moving away from bag-of-word models and word encoding toward word embeddings. The bene\ft of word embeddings is that they encode each word into a dense vector that captures something about its relative meaning within the training text. This means that variations of words like case, spelling, punctuation, and so on will automatically be learned to be similar in the embedding space.\n\nWord embedding is an approach to provide a ** dense vector representation ** of words that capture\nsomething about their meaning. \n\nWord embeddings are an improvement over simpler bag-of-word\nmodel word encoding schemes like word counts and frequencies that result in ** large and sparse\nvectors (mostly 0 values) ** that describe documents but not the meaning of the words.\n\n\nWord embeddings work by using an algorithm to train a set of ** fixed-length dense ** and\n** continuous-valued vectors ** based on a large corpus of text. Each word is represented by a\npoint in the embedding space and these points are learned and moved around based on the\nwords that surround the target word. \n\nIt is defining a word by the company that it keeps that\nallows the word embedding to learn something about the meaning of words. The vector space\nrepresentation of the words provides a projection where words with similar meanings are locally\nclustered within the space.\n\nThe use of word embeddings over other text representations is one of the key methods that\nhas led to breakthrough performance with deep neural networks on problems like machine\ntranslation.\n"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "Two approaches in this notebook: \n \n$$ Word2Vec $$ \n\nBy Google Researchers \n\n$$ GloVe $$\n\nBy Standford"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Gensim\nGensim is an open source Python library for natural language processing, with a focus on topic\nmodeling. It is billed as \\topic modeling for humans\". Gensim was developed and is maintained\nby the Czech natural language processing researcher Radim Rehurek. Most notably for this tutorial, it supports an implementation of the Word2Vec word embedding\nfor learning new word vectors from text."
        }, 
        {
            "cell_type": "code", 
            "metadata": {}, 
            "source": "import gensim", 
            "execution_count": 3, 
            "outputs": []
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Word2Vec\n\nWord2Vec is one algorithm for learning a word embedding from a text corpus. There are two\nmain training algorithms that can be used to learn the embedding from text; they are \n\n$$ Continuous-Bag-of-Words(CBOW) $$\n\n$$ Skip grams $$\n\nWe will not get into the algorithms other than to say\nthat they generally look at a window of words for each target word to provide context and in\nturn meaning for words. The approach was developed by Tomas Mikolov, formerly at Google\nand currently at Facebook.\n\nWord2Vec models require a lot of text, e.g. the entire Wikipedia corpus. Nevertheless, we\nwill demonstrate the principles using a small in-memory example of text. Gensim provides the\nWord2Vec class for working with a Word2Vec model. Learning a word embedding from text\ninvolves loading and organizing the text into sentences and providing them to the constructor\nof a new Word2Vec() instance. For example:"
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "source": "#Specifically, each sentence must be tokenized, meaning divided into words and prepared (e.g.\n#perhaps pre-filtered and perhaps converted to a preferred case).\n\nsentences = '...'\nmodel = Word2Vec(sentences)", 
            "execution_count": 8, 
            "outputs": [
                {
                    "output_type": "error", 
                    "traceback": [
                        "\u001b[0;31m\u001b[0m", 
                        "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-8-406d429490c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'...'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[0;31mNameError\u001b[0m: name 'Word2Vec' is not defined"
                    ], 
                    "evalue": "name 'Word2Vec' is not defined", 
                    "ename": "NameError"
                }
            ]
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "There are many parameters on this constructor; a few noteworthy arguments you may\nwish to con\fgure are:\n\u0088 \n\n- ** size **: (default 100) The number of dimensions of the embedding, e.g. the length of the dense vector to represent each token (word).\n\n- **window**: (default 5) The maximum distance between a target word and words around the target word.\n\u0088\n- **min count**: (default 5) The minimum count of words to consider when training the model; words with an occurrence less than this count will be ignored.\n- **workers**: (default 3) The number of threads to use while training.\n\n- **sg**: (default 0 or CBOW) The training algorithm, either CBOW (0) or skip gram (1)."
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "### TIPS: \nThe defaults are often good enough when just getting started. If you have a lot of cores, as\nmost modern computers do, I strongly encourage you to increase workers to match the number\nof cores (e.g. 8). After the model is trained, it is accessible via the \n\n$$ wv $$\n\nattribute. This is the\nactual word vector model in which queries can be made. For example, you can print the learned\nvocabulary of tokens (words) as follows:"
        }, 
        {
            "cell_type": "code", 
            "metadata": {}, 
            "source": "words = list(model.wv.vocab)\nprint(words)\n\n#You can review the embedded vector for a specific token as follows:\n\nprint(model['word'])\n\n#Finally, a trained model can then be saved to file by calling the save word2vec format()\n#function on the word vector model. By default, the model is saved in a binary format to save space. For example:\nmodel.wv.save_word2vec_format('model.bin')\n\n#When getting started, you can save the learned model in ASCII format and review the contents. You can do this by setting binary=False\n#For Examples:\n\nmodel.wv.save_word2vec_format('model.txt', binary=False)\n\n# The saved model can then be loaded again by calling the Word2Vec.load() function. For example:\nmodel = Word2Vec.load('model.bin')", 
            "execution_count": 10, 
            "outputs": [
                {
                    "output_type": "error", 
                    "traceback": [
                        "\u001b[0;31m\u001b[0m", 
                        "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-10-7aa0c63491e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#You can review the embedded vector for a specific token as follows:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
                    ], 
                    "evalue": "name 'model' is not defined", 
                    "ename": "NameError"
                }
            ]
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "We can tie all of this together with a worked example. Rather than loading a large text\ndocument or corpus from \fle, we will work with a small, in-memory list of pre-tokenized\nsentences."
        }, 
        {
            "cell_type": "code", 
            "metadata": {}, 
            "source": "from gensim.models import Word2Vec\n\n#defining data\nsentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n['this', 'is', 'the', 'second', 'sentence'],\n['yet', 'another', 'sentence'],\n['one', 'more', 'sentence'],\n['and', 'the', 'final', 'sentence']]\n\n# train model\nmodel = Word2Vec(sentences, min_count=1)\n\nprint (model)\n\n# summarize vocabulary\nwords = list(model.wv.vocab)\nprint(words)\n\n", 
            "execution_count": 16, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Word2Vec(vocab=14, size=100, alpha=0.025)\n['and', 'word2vec', 'for', 'sentence', 'this', 'is', 'one', 'second', 'another', 'the', 'first', 'yet', 'final', 'more']\n"
                }
            ]
        }, 
        {
            "cell_type": "code", 
            "metadata": {}, 
            "source": "# access vector for one word\nprint(model['sentence'])", 
            "execution_count": 17, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[  1.09108200e-03  -1.50774524e-03  -3.20697599e-03  -9.94841801e-04\n   3.15078214e-04   4.37214086e-03  -3.69665888e-03  -3.33983405e-03\n  -4.54258965e-03   9.99633805e-04  -4.23612585e-03  -3.83223081e-03\n   4.32860339e-03  -3.25149111e-03   2.95695267e-03  -3.71881900e-03\n  -1.00519822e-03   4.84643737e-03  -3.53238801e-03   1.22420708e-04\n  -4.58742678e-03   3.71732470e-03  -4.15829709e-03  -3.93305486e-03\n  -8.70488118e-04  -4.59041959e-03   3.76840495e-03  -3.98694444e-03\n   1.56842021e-03   4.36723279e-03   1.75691827e-03   1.42543553e-03\n  -3.02267703e-03   1.56308757e-03   1.13664242e-03  -1.06631417e-03\n   4.95949062e-03   1.51077483e-03  -3.55202728e-03  -1.73709460e-03\n  -4.47266269e-03  -3.67703475e-03   3.55967181e-03  -7.38290721e-04\n   7.48101273e-04   2.56760861e-03   8.07312434e-04  -2.70612515e-03\n  -4.23209416e-03   3.43392487e-03   9.29186004e-04   4.30594292e-03\n  -1.68683392e-03   2.32448475e-03  -3.98656679e-03   4.22142725e-03\n   3.05290613e-03   2.75243446e-03   4.32301033e-03  -3.94099904e-03\n  -2.20075296e-03  -2.56885798e-03  -4.12407611e-03  -1.56984746e-03\n  -3.00061726e-03  -3.19348928e-03   2.11892696e-03  -4.91847843e-03\n  -2.95917527e-03  -2.72088544e-03  -3.68361338e-03   4.82129958e-03\n  -3.23147955e-03   7.92523380e-04  -1.13938085e-03   4.13301494e-03\n  -2.28527421e-03   1.18826900e-03   4.92700469e-03   1.03034917e-03\n  -2.92705768e-03   2.56462279e-03   3.56607517e-04   3.56026203e-03\n   7.45267535e-05  -4.00806777e-04  -3.83335561e-03  -1.51982182e-03\n  -1.27809716e-03  -3.43685434e-03  -3.12654581e-03   2.05130153e-03\n  -4.02728189e-03  -3.57793015e-03  -1.95463211e-03  -1.00961013e-03\n   2.47778278e-03  -1.26721070e-03  -3.62945604e-03  -1.76866830e-03]\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/Applications/DataScienceStudio.app/Contents/Resources/kit/python.packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n  \n"
                }
            ]
        }, 
        {
            "cell_type": "code", 
            "metadata": {}, 
            "source": "# save model\nmodel.save('model.bin')\n# load model\nnew_model = Word2Vec.load('model.bin')\nprint(new_model)", 
            "execution_count": 18, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Word2Vec(vocab=14, size=100, alpha=0.025)\n"
                }
            ]
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Word Embedded Visualiazation\n\nAfter you learn word embedding for your text data, it can be nice to explore it with visualization.\nYou can use classical projection methods to reduce the high-dimensional word vectors to two-\ndimensional plots and plot them on a graph."
        }, 
        {
            "cell_type": "code", 
            "metadata": {}, 
            "source": "#We can retrieve all of the vectors from a trained model as follows\nX = model[model.wv.vocab]", 
            "execution_count": 19, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/Applications/DataScienceStudio.app/Contents/Resources/kit/python.packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n  \n"
                }
            ]
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "source": "from sklearn.decomposition import PCA\nfrom matplotlib import pyplot", 
            "execution_count": 20, 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "source": "#create a 2-dimensional PCA model of the word vectors using the scikit-learn PCA class\npca = PCA(n_components=2)\nresult = pca.fit_transform(X)\n", 
            "execution_count": 21, 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "metadata": {}, 
            "source": "#resulting projection can be plotted using Matplotlib as follows,\npyplot.scatter(result[:, 0], result[:, 1])", 
            "execution_count": 22, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "<matplotlib.collections.PathCollection at 0x112c51650>"
                    }, 
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "execution_count": 22
                }
            ]
        }, 
        {
            "cell_type": "code", 
            "metadata": {}, 
            "source": "#one step further and annotate the points on the graph with the words themselves.\nwords = list(model.wv.vocab)\nfor i, word in enumerate(words):\n    pyplot.annotate(word, xy=(result[i, 0], result[i, 1]))", 
            "execution_count": 24, 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "metadata": {}, 
            "source": "pyplot.show()", 
            "execution_count": 25, 
            "outputs": [
                {
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x1100e3290>"
                    }, 
                    "metadata": {}, 
                    "output_type": "display_data"
                }
            ]
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "source": "", 
            "execution_count": null, 
            "outputs": []
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "# Load Other Word Embedding for QuickStart\nTraining your own word vectors may be the best approach for a given NLP problem. But it\ncan take a long time, a fast computer with a lot of RAM and disk space, and perhaps some\nexpertise in \fnessing the input data and training algorithm. An alternative is to simply use an\nexisting pre-trained word embedding. \n\nA pre-trained model is nothing more than ** a file containing tokens and their associated word\nvectors. **\n\n## Google Word2Vec\n\nGoogle Word2Vec model was trained on Google news data (about 100\nbillion words); it contains 3 million words and phrases and was \ft using 300-dimensional word\nvectors. It is a 1.53 Gigabyte \fle. You can download it from here:GoogleNews-vectors-negative300.bin.gz.\nhttps://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n\n"
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "source": "# little linear algebra arithmetic with words. For example, \n#a popular example described in lectures and introduction papers is:\nqueen = (king - man) + woman", 
            "execution_count": 28, 
            "outputs": [
                {
                    "output_type": "error", 
                    "traceback": [
                        "\u001b[0;31m\u001b[0m", 
                        "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-28-15fad814170a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##Another interesting thing that you can do is do a little linear algebra arithmetic with words. For example, a popular example described in lectures and introduction papers is:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mqueen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mking\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mman\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwoman\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[0;31mNameError\u001b[0m: name 'king' is not defined"
                    ], 
                    "evalue": "name 'king' is not defined", 
                    "ename": "NameError"
                }
            ]
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "Running the example loads the Google pre-trained Word2Vec model and then calculates the\n(king - man) + woman = ? operation on the word vectors for those words. The answer, as we\nwould expect, is queen."
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "source": "from gensim.models import KeyedVectors\n# load the google word2vec model\nfilename = 'GoogleNews-vectors-negative300.bin'\nmodel = KeyedVectors.load_word2vec_format(filename, binary=True)\n# calculate: (king - man) + woman = ?\nresult = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\nprint(result)", 
            "execution_count": null, 
            "outputs": []
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "\n## Standford GloVe\nStanford researchers also have their own word embedding algorithm like Word2Vec called Global\nVectors for Word Representation, or GloVe for short.but generally, NLP practitioners seem to prefer GloVe at\nthe moment based on results.\n\nLike Word2Vec, the GloVe researchers also provide pre-trained word vectors, in this case, a\ngreat selection to choose from."
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "source": "from gensim.scripts.glove2word2vec import glove2word2vec\nglove_input_file = 'glove.txt'\nword2vec_output_file = 'word2vec.txt'\nglove2word2vec(glove_input_file, word2vec_output_file)", 
            "execution_count": 26, 
            "outputs": [
                {
                    "output_type": "error", 
                    "traceback": [
                        "\u001b[0;31m\u001b[0m", 
                        "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-26-d0237d64c41e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mglove_input_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'glove.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mword2vec_output_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'word2vec.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mglove2word2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_input_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2vec_output_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[0;32m/Users/timothycllam/Library/DataScienceStudio/dss_home/pyenv/lib/python2.7/site-packages/gensim/scripts/glove2word2vec.pyc\u001b[0m in \u001b[0;36mglove2word2vec\u001b[0;34m(glove_input_file, word2vec_output_file)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mglove2word2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_input_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2vec_output_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;34m\"\"\"Convert `glove_input_file` in GloVe format into `word2vec_output_file` in word2vec format.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mnum_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_glove_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_input_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"converting %i vectors from %s to %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglove_input_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2vec_output_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_output_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/Users/timothycllam/Library/DataScienceStudio/dss_home/pyenv/lib/python2.7/site-packages/gensim/scripts/glove2word2vec.pyc\u001b[0m in \u001b[0;36mget_glove_info\u001b[0;34m(glove_file_name)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_glove_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;34m\"\"\"Return the number of vectors and dimensions in a file in GloVe format.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_file_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mnum_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_file_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/Users/timothycllam/Library/DataScienceStudio/dss_home/pyenv/lib/python2.7/site-packages/smart_open/smart_open_lib.pyc\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_ERRORS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfile_smart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"s3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s3n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's3u'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0ms3_open_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/Users/timothycllam/Library/DataScienceStudio/dss_home/pyenv/lib/python2.7/site-packages/smart_open/smart_open_lib.pyc\u001b[0m in \u001b[0;36mfile_smart_open\u001b[0;34m(fname, mode, encoding, errors)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mraw_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m     \u001b[0mraw_fobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0mdecompressed_fobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_fobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0mdecoded_fobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecompressed_fobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'glove.txt'"
                    ], 
                    "evalue": "[Errno 2] No such file or directory: 'glove.txt'", 
                    "ename": "IOError"
                }
            ]
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "# Learn and Load Word Embeddings in Kera\n\n- About word embeddings and that Keras supports word embeddings via the Embedding layer.\n- How to learn a word embedding while \ftting a neural network.\n- How to use a pre-trained word embedding in a neural network."
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Keras Embedding Layer\nKeras offrs an Embedding layer that can be used for neural networks on text data. It requires\nthat the input data be integer encoded, so that each word is represented by a unique integer.\n\nThis data preparation step can be performed using the ** Tokenizer API ** also provided with Keras.\n\nThe Embedding layer is initialized with random weights and will learn an embedding for all\nof the words in the training dataset. \n\nIt is a flexible layer that can be used in a variety of ways, such as:\n\u0088 \n- It can be used alone to learn a word embedding that can be saved and used in another model later.\n- It can be used as part of a deep learning model where the embedding is learned along with the model itself.\n- It can be used to load a pre-trained word embedding model, a type of transfer learning."
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Embedding Layer in Hidden\nThe Embedding layer is de\fned as the \frst hidden layer of a network. It must specify 3 arguments:"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "** Input dim:**\n\nThis is the size of the vocabulary in the text data. For example, if your data\nis integer encoded to values between 0-10, then the size of the vocabulary would be 11\nwords.\n\n** Output dim:** \n\nThis is the size of the vector space in which words will be embedded. It\nde\fnes the size of the output vectors from this layer for each word. For example, it could\nbe 32 or 100 or even larger. Test di\u000berent values for your problem.\n\n** input length: **\n\nThis is the length of input sequences, as you would de\fne for any input\nlayer of a Keras model. For example, if all of your input documents are comprised of 1000\nwords, this would be 1000."
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "source": "e = Embedding(200, 32, input_length=50)", 
            "execution_count": null, 
            "outputs": []
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "For example, Above we de\fne an Embedding layer with a vocabulary of 200 (e.g. integer\nencoded words from 0 to 199, inclusive), a vector space of 32 dimensions in which words will be\nembedded, and input documents that have 50 words each."
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Connect to Dense Layer after Embedding\n### From 2D with weight to 1D array\nThe Embedding layer has weights that are learned. If you save your model to \fle, this will\ninclude weights for the Embedding layer. The output of the Embedding layer is a 2D vector with\none embedding for each word in the input sequence of words (input document). If you wish\nto connect a Dense layer directly to an Embedding layer, you must \frst \natten the 2D output\nmatrix to a 1D vector using the\n\n$$ Flatten-layer $$"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "# Simple Project\nIn this section, we will look at how we can learn a word embedding while \ftting a neural\nnetwork on a text classi\fcation problem. We will de\fne a small problem where we have 10\ntext documents, each with a comment about a piece of work a student submitted. Each text\ndocument is classi\fed as positive 1 or negative 0. This is a simple sentiment analysis problem.\nFirst, we will de\fne the documents and their class labels."
        }, 
        {
            "cell_type": "code", 
            "metadata": {}, 
            "source": "from keras.preprocessing.text import one_hot\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers.embeddings import Embedding", 
            "execution_count": 32, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n"
                }
            ]
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# define documents\ndocs = ['Well done!',\n'Good work',\n'Great effort',\n'nice work',\n'Excellent!',\n'Weak',\n'Poor effort!',\n'not good',\n'poor work',\n'Could have done better.']\n# define class labels\nlabels = [1,1,1,1,1,0,0,0,0,0]", 
            "execution_count": 29, 
            "outputs": []
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "Next, we can ** integer encode ** each document. \n\nThis means that as input the Embedding layer will have sequences of integers. \n\nWe could experiment with other more sophisticated bag of word model encoding like counts or ** TF-IDF **. \n\nKeras provides the ** one hot()** function that creates a hash of each word as an effcient integer encoding. \n\nWe will estimate the ** vocabulary size ** of 50, which is much larger than needed to reduce the probability of collisions from the hash function."
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "source": "# integer encode the documents\nvocab_size = 50\nencoded_docs = [one_hot(d, vocab_size) for d in docs]\nprint(encoded_docs)", 
            "execution_count": 33, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[[25, 48], [18, 22], [39, 3], [17, 22], [28], [37], [3, 3], [40, 18], [3, 22], [40, 19, 48, 4]]\n"
                }
            ]
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }, 
            "source": "### Sequence Length with Paddling\n\nThe sequences have di\u000berent lengths and Keras prefers inputs to be vectorized and all inputs\nto have the same length. We will pad all input sequences to have the length of 4. Again, we can\ndo this with a built in Keras function, in this case the pad sequences() function."
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "source": "# pad documents to a max length of 4 words\nmax_length = 4\npadded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\nprint(padded_docs)", 
            "execution_count": 34, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[[25 48  0  0]\n [18 22  0  0]\n [39  3  0  0]\n [17 22  0  0]\n [28  0  0  0]\n [37  0  0  0]\n [ 3  3  0  0]\n [40 18  0  0]\n [ 3 22  0  0]\n [40 19 48  4]]\n"
                }
            ]
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Put in Part of Neural Netork Model\n\nWe are now ready to de\fne our Embedding layer as part of our neural network model.\nThe Embedding layer has a vocabulary of 50 and an input length of 4. \n\nWe will choose a small embedding space of ** 8 dimensions. ** The model is a simple binary classi\fcation model.\n\n\nImportantly, the output from the Embedding layer will be 4 vectors of 8 dimensions each, one for each word. We  flatten this to a one 32-element vector to pass on to the Dense output layer.\n\n$$ 4 * 8 = 32 $$"
        }, 
        {
            "cell_type": "code", 
            "metadata": {}, 
            "source": "# define the model\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, 8, input_length=max_length))\nmodel.add(Flatten())\nmodel.add(Dense(1, activation='sigmoid'))\n# compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n# summarize the model\nmodel.summary()", 
            "execution_count": 35, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 4, 8)              400       \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 32)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 33        \n=================================================================\nTotal params: 433\nTrainable params: 433\nNon-trainable params: 0\n_________________________________________________________________\n"
                }
            ]
        }, 
        {
            "cell_type": "code", 
            "metadata": {}, 
            "source": "# fit the model\nmodel.fit(padded_docs, labels, epochs=40, verbose=0)\n# evaluate the model\nloss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\nprint('Accuracy: %f' % (accuracy*100))", 
            "execution_count": 39, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Accuracy: 100.000000\n"
                }
            ]
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "You could save the learned weights from the Embedding layer to \fle for later use in other\nmodels. You could also use this model generally to classify other documents that have the\nsame kind vocabulary seen in the test dataset."
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Reuse Pre-trained GloVe Embedding\n\nIt is common in the field of Natural Language Processing to learn, save, and make freely available word\nembeddings. For example, the researchers behind GloVe method provide a suite of pre-trained\nword embeddings on their website released under a public domain license."
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Download 800 MB file then run the sample\n\n\nThis example is inspired by an example in the Keras project: pretrained word embeddings.py.\nAfter downloading and unzipping, you will see a few \fles, one of which is glove.6B.100d.txt,\nwhich contains a 100-dimensional version of the embedding. If you peek inside the \fle, you will\nsee a token (word) followed by the weights (100 numbers) on each line. For example, below are\nthe \frst line of the embedding ASCII text \fle showing the embedding for the."
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "source": "from numpy import asarray\nfrom numpy import zeros\nfrom keras.preprocessing.text import Tokenizer\n", 
            "execution_count": 42, 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "source": "# define documents\ndocs = ['Well done!',\n'Good work',\n'Great effort',\n'nice work',\n'Excellent!',\n'Weak',\n'Poor effort!',\n'not good',\n'poor work',\n'Could have done better.']\n# define class labels\nlabels = [1,1,1,1,1,0,0,0,0,0]\n# prepare tokenizer\nt = Tokenizer()\nt.fit_on_texts(docs)\nvocab_size = len(t.word_index) + 1\n# integer encode the documents\nencoded_docs = t.texts_to_sequences(docs)\nprint(encoded_docs)\n# pad documents to a max length of 4 words\nmax_length = 4\npadded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\nprint(padded_docs)", 
            "execution_count": 43, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n[[ 6  2  0  0]\n [ 3  1  0  0]\n [ 7  4  0  0]\n [ 8  1  0  0]\n [ 9  0  0  0]\n [10  0  0  0]\n [ 5  4  0  0]\n [11  3  0  0]\n [ 5  1  0  0]\n [12 13  2 14]]\n"
                }
            ]
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Load the pre-trained GloVe data "
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# load the whole embedding into memory\nembeddings_index = dict()\nf = open('glove.6B.100d.txt')\n    for line in f:\n    values = line.split()\n    word = values[0]\n    coefs = asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\nprint('Loaded %s word vectors.' % len(embeddings_index))", 
            "execution_count": null, 
            "outputs": []
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "Next, we need to create a matrix of one embedding for each word in the training\ndataset. We can do that by ** enumerating all unique words in the Tokenizer.word index **\n\nLocating the embedding weight vector from the loaded GloVe embedding. The result is a matrix\nof weights only for words we will see during training."
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# create a weight matrix for words in training docs\nembedding_matrix = zeros((vocab_size, 100))\nfor word, i in t.word_index.items():\nembedding_vector = embeddings_index.get(word)\nif embedding_vector is not None:\nembedding_matrix[i] = embedding_vector", 
            "execution_count": null, 
            "outputs": []
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "Now we can define our model, fit, and evaluate it as before. \n\nThe key difference is that the Embedding layer can be seeded with the GloVe word embedding weights.\n\n** We chose the 100-dimensional version, therefore the Embedding layer must be defied with output dim set to 100 **\n\nFinally, we do not want to update the learned word weights in this model, therefore we  will set the trainable attribute for the model to be False."
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "source": "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)", 
            "execution_count": null, 
            "outputs": []
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## General Tips\n\nBy experience it is usually good to disconnect (or remove) punctuation from\nwords, and sometimes also convert all characters to lowercase. One can also replace\nall numbers (possibly greater than some constant) with some single token such as .\nAll these pre-processing steps aim to reduce the vocabulary size without removing\nany important content (which in some cases may not be true when you lowercase\ncertain words, ie. `Bush' is di\u000berent than `bush', while `Another' has usually the\nsame sense as `another'). The smaller the vocabulary is, the lower is the memory\ncomplexity, and the more robustly are the parameters for the words estimated. You\nalso have to pre-process the test data in the same way."
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 1.6 (Unsupported)", 
            "language": "python", 
            "name": "python2"
        }, 
        "language_info": {
            "version": "2.7.11", 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }, 
            "name": "python", 
            "pygments_lexer": "ipython2"
        }
    }, 
    "nbformat_minor": 1
}
